{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c23e4b42",
   "metadata": {},
   "source": [
    "\n",
    "Agents in Team\n",
    "\n",
    "\n",
    "A single Agent can only say create a short story for us.\n",
    "but with a team whre many agents work together towards a common goal they can help us in writing or even helping to review, edit etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df350c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5b90311",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_client=OpenAIChatCompletionClient(model=\"gemini-2.5-flash\",\n",
    "    api_key=\"AIzaSyDJtrGkMQcNF3HhPvPOws5xq_XtT4AgRis\",)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e188f1",
   "metadata": {},
   "source": [
    "## roundrobingroup chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa8e37d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "\n",
    "from autogen_agentchat.agents import AssistantAgent\n",
    "\n",
    "dsa_solver = AssistantAgent(\n",
    "    name = 'Complex_DSA_Solver',\n",
    "    model_client=model_client,\n",
    "    description='A DSA solver',\n",
    "    system_message=\"You give code in python to solve complex DSA problems. Give under 100 words.\"\n",
    ")\n",
    "\n",
    "code_reviewer = AssistantAgent(\n",
    "    name = 'CODE_REVIEWER',\n",
    "    model_client=model_client,\n",
    "    description='A Code Reviewer',\n",
    "    system_message=\"You review the code given by the complex_dsa_solver and make sure it is optimized.Give under 10 words. If you feel that the code is fine, please say 'TERMINATE'\"\n",
    ")\n",
    "\n",
    "code_editor = AssistantAgent(\n",
    "    name = 'CODE_EDITOR',\n",
    "    model_client=model_client,\n",
    "    description='A Code editor',\n",
    "    system_message=\"You make the code easy to understand and add comments wherever required.Give under 10 words\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a710b0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from autogen_agentchat.teams import RoundRobinGroupChat\n",
    "from autogen_agentchat.messages import TextMessage\n",
    "\n",
    "team = RoundRobinGroupChat(\n",
    "    participants=[dsa_solver, code_reviewer, code_editor],\n",
    "    max_turns=3   \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d22193d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "messages=[TextMessage(id='208a42e2-8315-4346-bf1c-79e8ec2b7689', source='user', models_usage=None, metadata={}, created_at=datetime.datetime(2025, 11, 27, 6, 3, 49, 314839, tzinfo=datetime.timezone.utc), content='write a simple code in python to add 2 numbers', type='TextMessage'), TextMessage(id='4ac32682-f5b6-4054-a9af-55db93d11b08', source='Complex_DSA_Solver', models_usage=RequestUsage(prompt_tokens=32, completion_tokens=41), metadata={}, created_at=datetime.datetime(2025, 11, 27, 6, 3, 51, 701693, tzinfo=datetime.timezone.utc), content='```python\\nnum1 = 5\\nnum2 = 10\\n\\nsum_result = num1 + num2\\n\\nprint(f\"The sum is: {sum_result}\")\\n```', type='TextMessage'), TextMessage(id='46040719-ee94-4e19-bae4-b0a065724c30', source='CODE_REVIEWER', models_usage=RequestUsage(prompt_tokens=97, completion_tokens=2), metadata={}, created_at=datetime.datetime(2025, 11, 27, 6, 3, 53, 837432, tzinfo=datetime.timezone.utc), content='TERMINATE', type='TextMessage'), TextMessage(id='906e5f64-fe8e-4787-8602-c792cac4f5d7', source='CODE_EDITOR', models_usage=RequestUsage(prompt_tokens=77, completion_tokens=69), metadata={}, created_at=datetime.datetime(2025, 11, 27, 6, 3, 55, 602314, tzinfo=datetime.timezone.utc), content='```python\\n# First number\\nnum1 = 5\\n# Second number\\nnum2 = 10\\n\\n# Add two numbers\\nsum_result = num1 + num2\\n\\n# Print the sum\\nprint(f\"The sum is: {sum_result}\")\\n```\\n**Adds two numbers and displays the total.**', type='TextMessage')] stop_reason='Maximum number of turns 3 reached.'\n"
     ]
    }
   ],
   "source": [
    "async def run_team():\n",
    "    task = TextMessage(content='write a simple code in python to add 2 numbers',source='user')\n",
    "\n",
    "    result = await team.run(task=task)\n",
    "\n",
    "\n",
    "    print(result)\n",
    "\n",
    "await run_team()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38e7e34",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'datetime' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m messages=[\n\u001b[32m      2\u001b[39m \n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     TextMessage(\u001b[38;5;28mid\u001b[39m=\u001b[33m'\u001b[39m\u001b[33m51a905cc-5572-43dd-98c3-53c2eed24b16\u001b[39m\u001b[33m'\u001b[39m, source=\u001b[33m'\u001b[39m\u001b[33muser\u001b[39m\u001b[33m'\u001b[39m, models_usage=\u001b[38;5;28;01mNone\u001b[39;00m, metadata={}, created_at=\u001b[43mdatetime\u001b[49m.datetime(\u001b[32m2025\u001b[39m, \u001b[32m7\u001b[39m, \u001b[32m12\u001b[39m, \u001b[32m4\u001b[39m, \u001b[32m40\u001b[39m, \u001b[32m29\u001b[39m, \u001b[32m124963\u001b[39m, tzinfo=datetime.timezone.utc), content=\u001b[33m'\u001b[39m\u001b[33mwrite a simple code in python to add 2 numbers\u001b[39m\u001b[33m'\u001b[39m, \u001b[38;5;28mtype\u001b[39m=\u001b[33m'\u001b[39m\u001b[33mTextMessage\u001b[39m\u001b[33m'\u001b[39m), \n\u001b[32m      4\u001b[39m \n\u001b[32m      5\u001b[39m \n\u001b[32m      6\u001b[39m     TextMessage(\u001b[38;5;28mid\u001b[39m=\u001b[33m'\u001b[39m\u001b[33m74116932-f287-43fe-a188-30a9992823b7\u001b[39m\u001b[33m'\u001b[39m, source=\u001b[33m'\u001b[39m\u001b[33mComplex_DSA_Solver\u001b[39m\u001b[33m'\u001b[39m, models_usage=RequestUsage(prompt_tokens=\u001b[32m40\u001b[39m, completion_tokens=\u001b[32m107\u001b[39m), metadata={}, created_at=datetime.datetime(\u001b[32m2025\u001b[39m, \u001b[32m7\u001b[39m, \u001b[32m12\u001b[39m, \u001b[32m4\u001b[39m, \u001b[32m40\u001b[39m, \u001b[32m32\u001b[39m, \u001b[32m949516\u001b[39m, tzinfo=datetime.timezone.utc), content=\u001b[33m'\u001b[39m\u001b[33mCertainly! Here is a simple Python code to add two numbers:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m```python\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m# Function to add two numbers\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mdef add_numbers(num1, num2):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m    return num1 + num2\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m# Example usage\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mnumber1 = 5\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mnumber2 = 3\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mresult = add_numbers(number1, number2)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mprint(\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mThe sum is:\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m, result)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m```\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mThis code defines a function `add_numbers` that takes two parameters and returns their sum. It then calls this function with example numbers and prints the result.\u001b[39m\u001b[33m'\u001b[39m, \u001b[38;5;28mtype\u001b[39m=\u001b[33m'\u001b[39m\u001b[33mTextMessage\u001b[39m\u001b[33m'\u001b[39m), \n\u001b[32m      7\u001b[39m \n\u001b[32m      8\u001b[39m \n\u001b[32m      9\u001b[39m     TextMessage(\u001b[38;5;28mid\u001b[39m=\u001b[33m'\u001b[39m\u001b[33mde6bf520-13d7-46c0-898d-249d9614dd73\u001b[39m\u001b[33m'\u001b[39m, source=\u001b[33m'\u001b[39m\u001b[33mCODE_REVIEWER\u001b[39m\u001b[33m'\u001b[39m, models_usage=RequestUsage(prompt_tokens=\u001b[32m163\u001b[39m, completion_tokens=\u001b[32m11\u001b[39m), metadata={}, created_at=datetime.datetime(\u001b[32m2025\u001b[39m, \u001b[32m7\u001b[39m, \u001b[32m12\u001b[39m, \u001b[32m4\u001b[39m, \u001b[32m40\u001b[39m, \u001b[32m34\u001b[39m, \u001b[32m347278\u001b[39m, tzinfo=datetime.timezone.utc), content=\u001b[33m'\u001b[39m\u001b[33mSimplify code; directly add variables without a function.\u001b[39m\u001b[33m'\u001b[39m, \u001b[38;5;28mtype\u001b[39m=\u001b[33m'\u001b[39m\u001b[33mTextMessage\u001b[39m\u001b[33m'\u001b[39m), \n\u001b[32m     10\u001b[39m \n\u001b[32m     11\u001b[39m \n\u001b[32m     12\u001b[39m \n\u001b[32m     13\u001b[39m     TextMessage(\u001b[38;5;28mid\u001b[39m=\u001b[33m'\u001b[39m\u001b[33m442cf157-9213-4f83-9077-4b0c1ff2896a\u001b[39m\u001b[33m'\u001b[39m, source=\u001b[33m'\u001b[39m\u001b[33mCODE_EDITOR\u001b[39m\u001b[33m'\u001b[39m, models_usage=RequestUsage(prompt_tokens=\u001b[32m178\u001b[39m, completion_tokens=\u001b[32m66\u001b[39m), metadata={}, created_at=datetime.datetime(\u001b[32m2025\u001b[39m, \u001b[32m7\u001b[39m, \u001b[32m12\u001b[39m, \u001b[32m4\u001b[39m, \u001b[32m40\u001b[39m, \u001b[32m36\u001b[39m, \u001b[32m402981\u001b[39m, tzinfo=datetime.timezone.utc), content=\u001b[33m'\u001b[39m\u001b[33mSure! Here\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[33ms a simplified version:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m```python\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m# Define two numbers\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mnumber1 = 5\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mnumber2 = 3\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m# Add the numbers\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mresult = number1 + number2\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m# Print the result\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mprint(\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mThe sum is:\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m, result)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m```\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mThis is straightforward, directly adding and printing the result.\u001b[39m\u001b[33m'\u001b[39m, \u001b[38;5;28mtype\u001b[39m=\u001b[33m'\u001b[39m\u001b[33mTextMessage\u001b[39m\u001b[33m'\u001b[39m)] \n\u001b[32m     17\u001b[39m     \u001b[38;5;66;03m#stop_reason='Maximum number of turns 3 reached.'\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'datetime' is not defined"
     ]
    }
   ],
   "source": [
    "messages=[\n",
    "    \n",
    "    TextMessage(id='51a905cc-5572-43dd-98c3-53c2eed24b16', source='user', models_usage=None, metadata={}, created_at=datetime.datetime(2025, 7, 12, 4, 40, 29, 124963, tzinfo=datetime.timezone.utc), content='write a simple code in python to add 2 numbers', type='TextMessage'), \n",
    "    \n",
    "    \n",
    "    TextMessage(id='74116932-f287-43fe-a188-30a9992823b7', source='Complex_DSA_Solver', models_usage=RequestUsage(prompt_tokens=40, completion_tokens=107), metadata={}, created_at=datetime.datetime(2025, 7, 12, 4, 40, 32, 949516, tzinfo=datetime.timezone.utc), content='Certainly! Here is a simple Python code to add two numbers:\\n\\n```python\\n# Function to add two numbers\\ndef add_numbers(num1, num2):\\n    return num1 + num2\\n\\n# Example usage\\nnumber1 = 5\\nnumber2 = 3\\nresult = add_numbers(number1, number2)\\n\\nprint(\"The sum is:\", result)\\n```\\n\\nThis code defines a function `add_numbers` that takes two parameters and returns their sum. It then calls this function with example numbers and prints the result.', type='TextMessage'), \n",
    "    \n",
    "    \n",
    "    TextMessage(id='de6bf520-13d7-46c0-898d-249d9614dd73', source='CODE_REVIEWER', models_usage=RequestUsage(prompt_tokens=163, completion_tokens=11), metadata={}, created_at=datetime.datetime(2025, 7, 12, 4, 40, 34, 347278, tzinfo=datetime.timezone.utc), content='Simplify code; directly add variables without a function.', type='TextMessage'), \n",
    "    \n",
    "    \n",
    "    \n",
    "    TextMessage(id='442cf157-9213-4f83-9077-4b0c1ff2896a', source='CODE_EDITOR', models_usage=RequestUsage(prompt_tokens=178, completion_tokens=66), metadata={}, created_at=datetime.datetime(2025, 7, 12, 4, 40, 36, 402981, tzinfo=datetime.timezone.utc), content='Sure! Here\\'s a simplified version:\\n\\n```python\\n# Define two numbers\\nnumber1 = 5\\nnumber2 = 3\\n\\n# Add the numbers\\nresult = number1 + number2\\n\\n# Print the result\\nprint(\"The sum is:\", result)\\n```\\n\\nThis is straightforward, directly adding and printing the result.', type='TextMessage')] \n",
    "    \n",
    "    \n",
    "    \n",
    "    #stop_reason='Maximum number of turns 3 reached.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af55545b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "messages=[TextMessage(id='8444d7f4-a290-4649-979e-dc81204880e2', source='user', models_usage=None, metadata={}, created_at=datetime.datetime(2025, 11, 27, 6, 4, 2, 968569, tzinfo=datetime.timezone.utc), content='write a simple code in python to add 2 numbers', type='TextMessage'), TextMessage(id='f114d2ab-403f-452a-9745-9f2863d83160', source='Complex_DSA_Solver', models_usage=RequestUsage(prompt_tokens=86, completion_tokens=87), metadata={}, created_at=datetime.datetime(2025, 11, 27, 6, 4, 4, 687144, tzinfo=datetime.timezone.utc), content='```python\\ndef add_two_numbers(a, b):\\n  \"\"\"Adds two numbers and returns their sum.\"\"\"\\n  return a + b\\n\\n# Example usage:\\nnumber1 = 7\\nnumber2 = 3\\n\\nresult = add_two_numbers(number1, number2)\\nprint(f\"The sum of {number1} and {number2} is: {result}\")\\n```', type='TextMessage')] stop_reason='Maximum number of turns 1 reached.'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from autogen_agentchat.teams import RoundRobinGroupChat\n",
    "from autogen_agentchat.messages import TextMessage\n",
    "\n",
    "team = RoundRobinGroupChat(\n",
    "    participants=[dsa_solver, code_reviewer, code_editor],\n",
    "    max_turns=1   \n",
    ")\n",
    "\n",
    "\n",
    "async def run_team():\n",
    "    task = TextMessage(content='write a simple code in python to add 2 numbers',source='user')\n",
    "\n",
    "    result = await team.run(task=task)\n",
    "\n",
    "\n",
    "    print(result)\n",
    "\n",
    "await run_team()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d08584",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages=[\n",
    "    \n",
    "    \n",
    "    TextMessage(id='15328376-2a2b-4375-8e18-b31afd6cc8ca', source='user', models_usage=None, metadata={}, created_at=datetime.datetime(2025, 7, 12, 4, 46, 49, 990748, tzinfo=datetime.timezone.utc), content='write a simple code in python to add 2 numbers', type='TextMessage'), \n",
    "          \n",
    "    1 .TextMessage(id='af44b30c-ea76-46db-a20d-acf74f379aee', source='Complex_DSA_Solver', models_usage=RequestUsage(prompt_tokens=167, completion_tokens=92), metadata={}, created_at=datetime.datetime(2025, 7, 12, 4, 46, 51, 883189, tzinfo=datetime.timezone.utc), content='Sure! Here is a simple Python code to add two numbers:\\n\\n```python\\n# Input two numbers\\nnum1 = float(input(\"Enter first number: \"))\\nnum2 = float(input(\"Enter second number: \"))\\n\\n# Calculate the sum\\nsum = num1 + num2\\n\\n# Print the result\\nprint(\"The sum is:\", sum)\\n```\\n\\nThis code takes two numbers as input from the user, calculates their sum, and prints the result.', type='TextMessage')\n",
    "    \n",
    "          ] stop_reason='Maximum number of turns 1 reached.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b5c326b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "messages=[TextMessage(id='f979175d-9e67-4055-bb50-fe88d5afd4ae', source='user', models_usage=None, metadata={}, created_at=datetime.datetime(2025, 11, 27, 6, 4, 7, 784831, tzinfo=datetime.timezone.utc), content='write a simple code in python to add 2 numbers', type='TextMessage'), TextMessage(id='d439ee63-3400-461b-ac57-dcf50f0f42ca', source='Complex_DSA_Solver', models_usage=RequestUsage(prompt_tokens=186, completion_tokens=77), metadata={}, created_at=datetime.datetime(2025, 11, 27, 6, 4, 9, 681384, tzinfo=datetime.timezone.utc), content='```python\\n# Get input from the user\\nnum1 = float(input(\"Enter the first number: \"))\\nnum2 = float(input(\"Enter the second number: \"))\\n\\n# Add the numbers\\nsum_of_numbers = num1 + num2\\n\\n# Display the result\\nprint(f\"The sum is: {sum_of_numbers}\")\\n```', type='TextMessage'), TextMessage(id='cd1738fe-1a31-4577-92c6-c2104bb5acc9', source='CODE_REVIEWER', models_usage=RequestUsage(prompt_tokens=190, completion_tokens=2), metadata={}, created_at=datetime.datetime(2025, 11, 27, 6, 4, 10, 709210, tzinfo=datetime.timezone.utc), content='TERMINATE', type='TextMessage'), TextMessage(id='14d0dbb2-b723-4664-8a96-090c477f638b', source='CODE_EDITOR', models_usage=RequestUsage(prompt_tokens=240, completion_tokens=108), metadata={}, created_at=datetime.datetime(2025, 11, 27, 6, 4, 12, 814700, tzinfo=datetime.timezone.utc), content='```python\\n# Get input from the user for the first number\\nnum1 = float(input(\"Enter the first number: \"))\\n# Get input from the user for the second number\\nnum2 = float(input(\"Enter the second number: \"))\\n\\n# Add the two numbers together\\nsum_of_numbers = num1 + num2\\n\\n# Display the calculated sum\\nprint(f\"The sum is: {sum_of_numbers}\")\\n```\\n**Adds two user-entered numbers and prints the total.**', type='TextMessage'), TextMessage(id='59960a46-12fe-42d0-ae0e-ada890b9aaaf', source='Complex_DSA_Solver', models_usage=RequestUsage(prompt_tokens=376, completion_tokens=14), metadata={}, created_at=datetime.datetime(2025, 11, 27, 6, 4, 14, 60560, tzinfo=datetime.timezone.utc), content='Understood. I will terminate providing further examples for adding two numbers.', type='TextMessage'), TextMessage(id='87b95c7c-3f0a-4f29-81ec-4504fd0e20f4', source='CODE_REVIEWER', models_usage=RequestUsage(prompt_tokens=317, completion_tokens=2), metadata={}, created_at=datetime.datetime(2025, 11, 27, 6, 4, 15, 63525, tzinfo=datetime.timezone.utc), content='TERMINATE', type='TextMessage'), TextMessage(id='7bf7cf83-e0ef-4231-8e11-8333e79b8261', source='CODE_EDITOR', models_usage=RequestUsage(prompt_tokens=367, completion_tokens=4), metadata={}, created_at=datetime.datetime(2025, 11, 27, 6, 4, 16, 431174, tzinfo=datetime.timezone.utc), content='Okay, understood.', type='TextMessage')] stop_reason='Maximum number of turns 6 reached.'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from autogen_agentchat.teams import RoundRobinGroupChat\n",
    "from autogen_agentchat.messages import TextMessage\n",
    "\n",
    "team = RoundRobinGroupChat(\n",
    "    participants=[dsa_solver, code_reviewer, code_editor],\n",
    "    max_turns=6  \n",
    ")\n",
    "\n",
    "\n",
    "async def run_team():\n",
    "    task = TextMessage(content='write a simple code in python to add 2 numbers',source='user')\n",
    "\n",
    "    result = await team.run(task=task)\n",
    "\n",
    "\n",
    "    print(result)\n",
    "\n",
    "await run_team()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "addd489c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "messages=[\n",
    "    \n",
    "    TextMessage(id='d24509ac-1a54-407f-9a29-90e72c2d89e7', source='user', models_usage=None, metadata={}, created_at=datetime.datetime(2025, 7, 12, 4, 48, 30, 725154, tzinfo=datetime.timezone.utc), content='write a simple code in python to add 2 numbers', type='TextMessage'), \n",
    "    \n",
    "   1.  TextMessage(id='6c524b7e-7d40-4954-9d1f-8988befa9902', source='Complex_DSA_Solver', models_usage=RequestUsage(prompt_tokens=279, completion_tokens=76), metadata={}, created_at=datetime.datetime(2025, 7, 12, 4, 48, 32, 224395, tzinfo=datetime.timezone.utc), content='Certainly! Here is a straightforward Python code to add two numbers:\\n\\n```python\\n# Define two numbers\\nnum1 = 10\\nnum2 = 15\\n\\n# Calculate the sum\\nsum = num1 + num2\\n\\n# Print the result\\nprint(\"The sum is:\", sum)\\n```\\n\\nThis script defines two numbers, calculates their sum, and prints the result.', type='TextMessage'), \n",
    "    \n",
    "    \n",
    "    2. TextMessage(id='42af9a71-3f69-40d9-be0a-3975c62c6759', source='CODE_REVIEWER', models_usage=RequestUsage(prompt_tokens=280, completion_tokens=15), metadata={}, created_at=datetime.datetime(2025, 7, 12, 4, 48, 33, 363036, tzinfo=datetime.timezone.utc), content='Directly print the sum: `print(num1 + num2)`.', type='TextMessage'), \n",
    "    \n",
    "    \n",
    "    3. TextMessage(id='ba70f62d-cd20-456e-8c6e-45131fcd8322', source='CODE_EDITOR', models_usage=RequestUsage(prompt_tokens=374, completion_tokens=60), metadata={}, created_at=datetime.datetime(2025, 7, 12, 4, 48, 36, 218566, tzinfo=datetime.timezone.utc), content='Certainly! Here\\'s an even simpler version:\\n\\n```python\\n# Define two numbers\\nnum1 = 10\\nnum2 = 15\\n\\n# Directly print the sum\\nprint(\"The sum is:\", num1 + num2)\\n```\\n\\nThis version directly prints the sum of the two numbers.', type='TextMessage'), \n",
    "    \n",
    "    \n",
    "    4. TextMessage(id='be7b5772-b79f-480c-b142-bda95c3aae5c', source='Complex_DSA_Solver', models_usage=RequestUsage(prompt_tokens=450, completion_tokens=59), metadata={}, created_at=datetime.datetime(2025, 7, 12, 4, 48, 37, 631782, tzinfo=datetime.timezone.utc), content=\"Great suggestion! Here's the revised code with direct printing:\\n\\n```python\\n# Define two numbers\\nnum1 = 10\\nnum2 = 15\\n\\n# Directly print the sum\\nprint(num1 + num2)\\n```\\n\\nThis code eliminates the intermediate variable and prints the sum directly.\", type='TextMessage'), \n",
    "    \n",
    "    \n",
    "    5. TextMessage(id='25f541bc-39a6-468e-be9b-c5967a1c999b', source='CODE_REVIEWER', models_usage=RequestUsage(prompt_tokens=435, completion_tokens=16), metadata={}, created_at=datetime.datetime(2025, 7, 12, 4, 48, 38, 834616, tzinfo=datetime.timezone.utc), content='Eliminate comments; directly print: `print(10 + 15)`.', type='TextMessage'), \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    6. TextMessage(id='11f799c8-ae0e-4803-9851-af173929bca6', source='CODE_EDITOR', models_usage=RequestUsage(prompt_tokens=532, completion_tokens=36), metadata={}, created_at=datetime.datetime(2025, 7, 12, 4, 48, 40, 433738, tzinfo=datetime.timezone.utc), content=\"Sure! Here's the simplest version:\\n\\n```python\\nprint(10 + 15)\\n```\\n\\nThis directly prints the sum of 10 and 15 without additional variables or comments.\", type='TextMessage')] \n",
    "\n",
    "\n",
    "stop_reason='Maximum number of turns 6 reached.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "34d50f30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user : write a simple code in python to add 2 numbers\n",
      "Complex_DSA_Solver : ```python\n",
      "# Define two numbers\n",
      "a = 25\n",
      "b = 15\n",
      "\n",
      "# Calculate their sum\n",
      "total = a + b\n",
      "\n",
      "# Print the result\n",
      "print(f\"{a} + {b} = {total}\")\n",
      "```\n",
      "CODE_REVIEWER : TERMINATE\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from autogen_agentchat.teams import RoundRobinGroupChat\n",
    "from autogen_agentchat.messages import TextMessage\n",
    "from autogen_agentchat.conditions import TextMentionTermination\n",
    "\n",
    "\n",
    "my_termination = TextMentionTermination(text='TERMINATE')\n",
    "\n",
    "team = RoundRobinGroupChat(\n",
    "    participants=[dsa_solver, code_reviewer, code_editor],\n",
    "    termination_condition=my_termination,\n",
    "    max_turns=14  \n",
    ")\n",
    "\n",
    "\n",
    "async def run_team():\n",
    "    task = TextMessage(content='write a simple code in python to add 2 numbers',source='user')\n",
    "\n",
    "    result = await team.run(task=task)\n",
    "\n",
    "    for each_agent_message in result.messages:\n",
    "        print(f\"{each_agent_message.source} : {each_agent_message.content}\")\n",
    "\n",
    "\n",
    "    # print(result)\n",
    "await run_team()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b2430c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user : write a code to find median of two sorted arrays\n",
      "Complex_DSA_Solver : ```python\n",
      "class Solution:\n",
      "    def findMedianSortedArrays(self, nums1: list[int], nums2: list[int]) -> float:\n",
      "        # Ensure nums1 is the shorter array for optimized binary search\n",
      "        if len(nums1) > len(nums2):\n",
      "            nums1, nums2 = nums2, nums1\n",
      "\n",
      "        m, n = len(nums1), len(nums2)\n",
      "        low, high = 0, m\n",
      "        half_len = (m + n + 1) // 2 # Total elements needed on the left partition\n",
      "\n",
      "        while low <= high:\n",
      "            partitionX = (low + high) // 2\n",
      "            partitionY = half_len - partitionX\n",
      "\n",
      "            # Define boundary elements for comparison\n",
      "            maxX = float('-inf') if partitionX == 0 else nums1[partitionX - 1]\n",
      "            minX = float('inf') if partitionX == m else nums1[partitionX]\n",
      "            maxY = float('-inf') if partitionY == 0 else nums2[partitionY - 1]\n",
      "            minY = float('inf') if partitionY == n else nums2[partitionY]\n",
      "\n",
      "            if maxX <= minY and maxY <= minX: # Correct partition found\n",
      "                if (m + n) % 2 == 0:\n",
      "                    return (max(maxX, maxY) + min(minX, minY)) / 2\n",
      "                else:\n",
      "                    return float(max(maxX, maxY))\n",
      "            elif maxX > minY: # partitionX is too far right\n",
      "                high = partitionX - 1\n",
      "            else: # maxY > minX, partitionX is too far left\n",
      "                low = partitionX + 1\n",
      "        return 0.0 # Should not be reached with valid inputs\n",
      "\n",
      "```\n",
      "This binary search solution (O(log(min(m,n)))) finds the median of two sorted arrays without merging. It intelligently partitions both arrays to locate the elements that would be at the median position, then calculates the median from these partition boundaries.\n"
     ]
    }
   ],
   "source": [
    "from autogen_agentchat.teams import RoundRobinGroupChat\n",
    "from autogen_agentchat.messages import TextMessage\n",
    "from autogen_agentchat.conditions import TextMentionTermination,MaxMessageTermination\n",
    "\n",
    "\n",
    "my_termination = TextMentionTermination(text='TERMINATE') | MaxMessageTermination(max_messages=2)#stop where the message source is 2 including textmesaage from user\n",
    "\n",
    "team = RoundRobinGroupChat(\n",
    "    participants=[dsa_solver, code_reviewer, code_editor],\n",
    "    termination_condition=my_termination,\n",
    "    max_turns=6 #doesnot include user text mesage\n",
    ")\n",
    "\n",
    "\n",
    "async def run_team():\n",
    "    task = TextMessage(content='write a code to find median of two sorted arrays',source='user')\n",
    "\n",
    "    result = await team.run(task=task)\n",
    "\n",
    "    for each_agent_message in result.messages:\n",
    "        print(f\"{each_agent_message.source} : {each_agent_message.content}\")\n",
    "\n",
    "\n",
    "    # print(result)\n",
    "\n",
    "await run_team()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c31a94ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'autogen_agentchat.messages.TextMessage'>\n",
      "user id='95d2b387-498b-40d0-9df0-e739cea66be6' source='user' models_usage=None metadata={} created_at=datetime.datetime(2025, 11, 27, 6, 4, 28, 118926, tzinfo=datetime.timezone.utc) content='Write a simple Hello world code ?' type='TextMessage'\n",
      "<class 'autogen_agentchat.messages.TextMessage'>\n",
      "Complex_DSA_Solver id='a5b648b5-0f7f-4d50-b9b0-5d3d32785559' source='Complex_DSA_Solver' models_usage=RequestUsage(prompt_tokens=914, completion_tokens=11) metadata={} created_at=datetime.datetime(2025, 11, 27, 6, 4, 29, 347781, tzinfo=datetime.timezone.utc) content='```python\\nprint(\"Hello, World!\")\\n```' type='TextMessage'\n",
      "<class 'autogen_agentchat.base._task.TaskResult'>\n",
      "Stop Reason: Maximum number of messages 2 reached, current message count: 2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from autogen_agentchat.base import TaskResult#type of last message\n",
    "\n",
    "\n",
    "team_2 = RoundRobinGroupChat(\n",
    "    participants=[dsa_solver, code_reviewer, code_editor],\n",
    "    termination_condition=my_termination,\n",
    "    max_turns=6\n",
    ")\n",
    "\n",
    "\n",
    "async for message in team_2.run_stream(task=\"Write a simple Hello world code ?\"):  # type: ignore\n",
    "\n",
    "    print(type(message))\n",
    "    if isinstance(message, TaskResult):\n",
    "        print(\"Stop Reason:\", message.stop_reason)\n",
    "    else:\n",
    "        print(message.source,message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2dbc4908",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error processing publish message for Complex_DSA_Solver_b301ac24-8a8e-43ee-924f-1019f7ea903c/b301ac24-8a8e-43ee-924f-1019f7ea903c\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\judirispah\\anaconda3\\envs\\agent\\Lib\\site-packages\\autogen_core\\_single_threaded_agent_runtime.py\", line 606, in _on_message\n",
      "    return await agent.on_message(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<2 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\judirispah\\anaconda3\\envs\\agent\\Lib\\site-packages\\autogen_core\\_base_agent.py\", line 119, in on_message\n",
      "    return await self.on_message_impl(message, ctx)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\judirispah\\anaconda3\\envs\\agent\\Lib\\site-packages\\autogen_agentchat\\teams\\_group_chat\\_sequential_routed_agent.py\", line 67, in on_message_impl\n",
      "    return await super().on_message_impl(message, ctx)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\judirispah\\anaconda3\\envs\\agent\\Lib\\site-packages\\autogen_core\\_routed_agent.py\", line 485, in on_message_impl\n",
      "    return await h(self, message, ctx)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\judirispah\\anaconda3\\envs\\agent\\Lib\\site-packages\\autogen_core\\_routed_agent.py\", line 268, in wrapper\n",
      "    return_value = await func(self, message, ctx)  # type: ignore\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\judirispah\\anaconda3\\envs\\agent\\Lib\\site-packages\\autogen_agentchat\\teams\\_group_chat\\_chat_agent_container.py\", line 84, in handle_request\n",
      "    async for msg in self._agent.on_messages_stream(self._message_buffer, ctx.cancellation_token):\n",
      "    ...<4 lines>...\n",
      "            await self._log_message(msg)\n",
      "  File \"c:\\Users\\judirispah\\anaconda3\\envs\\agent\\Lib\\site-packages\\autogen_agentchat\\agents\\_assistant_agent.py\", line 953, in on_messages_stream\n",
      "    async for inference_output in self._call_llm(\n",
      "    ...<15 lines>...\n",
      "            yield inference_output\n",
      "  File \"c:\\Users\\judirispah\\anaconda3\\envs\\agent\\Lib\\site-packages\\autogen_agentchat\\agents\\_assistant_agent.py\", line 1107, in _call_llm\n",
      "    model_result = await model_client.create(\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<4 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\judirispah\\anaconda3\\envs\\agent\\Lib\\site-packages\\autogen_ext\\models\\openai\\_openai_client.py\", line 676, in create\n",
      "    result: Union[ParsedChatCompletion[BaseModel], ChatCompletion] = await future\n",
      "                                                                     ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\judirispah\\anaconda3\\envs\\agent\\Lib\\site-packages\\openai\\resources\\chat\\completions\\completions.py\", line 2028, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "    ...<45 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\judirispah\\anaconda3\\envs\\agent\\Lib\\site-packages\\openai\\_base_client.py\", line 1748, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\judirispah\\anaconda3\\envs\\agent\\Lib\\site-packages\\openai\\_base_client.py\", line 1555, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - [{'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 10, model: gemini-2.5-flash\\nPlease retry in 28.261112209s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '10'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '28s'}]}}]\n",
      "Error processing publish message for CODE_REVIEWER_b301ac24-8a8e-43ee-924f-1019f7ea903c/b301ac24-8a8e-43ee-924f-1019f7ea903c\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\judirispah\\anaconda3\\envs\\agent\\Lib\\site-packages\\autogen_core\\_single_threaded_agent_runtime.py\", line 606, in _on_message\n",
      "    return await agent.on_message(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<2 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\judirispah\\anaconda3\\envs\\agent\\Lib\\site-packages\\autogen_core\\_base_agent.py\", line 119, in on_message\n",
      "    return await self.on_message_impl(message, ctx)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\judirispah\\anaconda3\\envs\\agent\\Lib\\site-packages\\autogen_agentchat\\teams\\_group_chat\\_sequential_routed_agent.py\", line 72, in on_message_impl\n",
      "    return await super().on_message_impl(message, ctx)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\judirispah\\anaconda3\\envs\\agent\\Lib\\site-packages\\autogen_core\\_routed_agent.py\", line 486, in on_message_impl\n",
      "    return await self.on_unhandled_message(message, ctx)  # type: ignore\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\judirispah\\anaconda3\\envs\\agent\\Lib\\site-packages\\autogen_agentchat\\teams\\_group_chat\\_chat_agent_container.py\", line 138, in on_unhandled_message\n",
      "    raise ValueError(f\"Unhandled message in agent container: {type(message)}\")\n",
      "ValueError: Unhandled message in agent container: <class 'autogen_agentchat.teams._group_chat._events.GroupChatError'>\n",
      "Error processing publish message for CODE_EDITOR_b301ac24-8a8e-43ee-924f-1019f7ea903c/b301ac24-8a8e-43ee-924f-1019f7ea903c\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\judirispah\\anaconda3\\envs\\agent\\Lib\\site-packages\\autogen_core\\_single_threaded_agent_runtime.py\", line 606, in _on_message\n",
      "    return await agent.on_message(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<2 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\judirispah\\anaconda3\\envs\\agent\\Lib\\site-packages\\autogen_core\\_base_agent.py\", line 119, in on_message\n",
      "    return await self.on_message_impl(message, ctx)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\judirispah\\anaconda3\\envs\\agent\\Lib\\site-packages\\autogen_agentchat\\teams\\_group_chat\\_sequential_routed_agent.py\", line 72, in on_message_impl\n",
      "    return await super().on_message_impl(message, ctx)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\judirispah\\anaconda3\\envs\\agent\\Lib\\site-packages\\autogen_core\\_routed_agent.py\", line 486, in on_message_impl\n",
      "    return await self.on_unhandled_message(message, ctx)  # type: ignore\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\judirispah\\anaconda3\\envs\\agent\\Lib\\site-packages\\autogen_agentchat\\teams\\_group_chat\\_chat_agent_container.py\", line 138, in on_unhandled_message\n",
      "    raise ValueError(f\"Unhandled message in agent container: {type(message)}\")\n",
      "ValueError: Unhandled message in agent container: <class 'autogen_agentchat.teams._group_chat._events.GroupChatError'>\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "RateLimitError: Error code: 429 - [{'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 10, model: gemini-2.5-flash\\nPlease retry in 28.261112209s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '10'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '28s'}]}}]\nTraceback:\nTraceback (most recent call last):\n\n  File \"c:\\Users\\judirispah\\anaconda3\\envs\\agent\\Lib\\site-packages\\autogen_agentchat\\teams\\_group_chat\\_chat_agent_container.py\", line 84, in handle_request\n    async for msg in self._agent.on_messages_stream(self._message_buffer, ctx.cancellation_token):\n    ...<4 lines>...\n            await self._log_message(msg)\n\n  File \"c:\\Users\\judirispah\\anaconda3\\envs\\agent\\Lib\\site-packages\\autogen_agentchat\\agents\\_assistant_agent.py\", line 953, in on_messages_stream\n    async for inference_output in self._call_llm(\n    ...<15 lines>...\n            yield inference_output\n\n  File \"c:\\Users\\judirispah\\anaconda3\\envs\\agent\\Lib\\site-packages\\autogen_agentchat\\agents\\_assistant_agent.py\", line 1107, in _call_llm\n    model_result = await model_client.create(\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^\n    ...<4 lines>...\n    )\n    ^\n\n  File \"c:\\Users\\judirispah\\anaconda3\\envs\\agent\\Lib\\site-packages\\autogen_ext\\models\\openai\\_openai_client.py\", line 676, in create\n    result: Union[ParsedChatCompletion[BaseModel], ChatCompletion] = await future\n                                                                     ^^^^^^^^^^^^\n\n  File \"c:\\Users\\judirispah\\anaconda3\\envs\\agent\\Lib\\site-packages\\openai\\resources\\chat\\completions\\completions.py\", line 2028, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n    ...<45 lines>...\n    )\n    ^\n\n  File \"c:\\Users\\judirispah\\anaconda3\\envs\\agent\\Lib\\site-packages\\openai\\_base_client.py\", line 1748, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"c:\\Users\\judirispah\\anaconda3\\envs\\agent\\Lib\\site-packages\\openai\\_base_client.py\", line 1555, in request\n    raise self._make_status_error_from_response(err.response) from None\n\nopenai.RateLimitError: Error code: 429 - [{'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 10, model: gemini-2.5-flash\\nPlease retry in 28.261112209s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '10'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '28s'}]}}]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 25\u001b[39m\n\u001b[32m     20\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00meach_agent_message.source\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00meach_agent_message.content\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     23\u001b[39m     \u001b[38;5;66;03m# print(result)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m run_team()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 17\u001b[39m, in \u001b[36mrun_team\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrun_team\u001b[39m():\n\u001b[32m     15\u001b[39m     task = TextMessage(content=\u001b[33m'\u001b[39m\u001b[33mwrite a code to add 2 numbers. TERMINATE\u001b[39m\u001b[33m'\u001b[39m,source=\u001b[33m'\u001b[39m\u001b[33muser\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m     result = \u001b[38;5;28;01mawait\u001b[39;00m team.run(task=task)\n\u001b[32m     19\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m each_agent_message \u001b[38;5;129;01min\u001b[39;00m result.messages:\n\u001b[32m     20\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00meach_agent_message.source\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00meach_agent_message.content\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\judirispah\\anaconda3\\envs\\agent\\Lib\\site-packages\\autogen_agentchat\\teams\\_group_chat\\_base_group_chat.py:308\u001b[39m, in \u001b[36mBaseGroupChat.run\u001b[39m\u001b[34m(self, task, cancellation_token, output_task_messages)\u001b[39m\n\u001b[32m    222\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Run the team and return the result. The base implementation uses\u001b[39;00m\n\u001b[32m    223\u001b[39m \u001b[33;03m:meth:`run_stream` to run the team and then returns the final result.\u001b[39;00m\n\u001b[32m    224\u001b[39m \u001b[33;03mOnce the team is stopped, the termination condition is reset.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    305\u001b[39m \u001b[33;03m    asyncio.run(main())\u001b[39;00m\n\u001b[32m    306\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    307\u001b[39m result: TaskResult | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m308\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m message \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.run_stream(\n\u001b[32m    309\u001b[39m     task=task,\n\u001b[32m    310\u001b[39m     cancellation_token=cancellation_token,\n\u001b[32m    311\u001b[39m     output_task_messages=output_task_messages,\n\u001b[32m    312\u001b[39m ):\n\u001b[32m    313\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(message, TaskResult):\n\u001b[32m    314\u001b[39m         result = message\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\judirispah\\anaconda3\\envs\\agent\\Lib\\site-packages\\autogen_agentchat\\teams\\_group_chat\\_base_group_chat.py:522\u001b[39m, in \u001b[36mBaseGroupChat.run_stream\u001b[39m\u001b[34m(self, task, cancellation_token, output_task_messages)\u001b[39m\n\u001b[32m    518\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(message, GroupChatTermination):\n\u001b[32m    519\u001b[39m     \u001b[38;5;66;03m# If the message contains an error, we need to raise it here.\u001b[39;00m\n\u001b[32m    520\u001b[39m     \u001b[38;5;66;03m# This will stop the team and propagate the error.\u001b[39;00m\n\u001b[32m    521\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m message.error \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m522\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;28mstr\u001b[39m(message.error))\n\u001b[32m    523\u001b[39m     stop_reason = message.message.content\n\u001b[32m    524\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[31mRuntimeError\u001b[39m: RateLimitError: Error code: 429 - [{'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 10, model: gemini-2.5-flash\\nPlease retry in 28.261112209s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '10'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '28s'}]}}]\nTraceback:\nTraceback (most recent call last):\n\n  File \"c:\\Users\\judirispah\\anaconda3\\envs\\agent\\Lib\\site-packages\\autogen_agentchat\\teams\\_group_chat\\_chat_agent_container.py\", line 84, in handle_request\n    async for msg in self._agent.on_messages_stream(self._message_buffer, ctx.cancellation_token):\n    ...<4 lines>...\n            await self._log_message(msg)\n\n  File \"c:\\Users\\judirispah\\anaconda3\\envs\\agent\\Lib\\site-packages\\autogen_agentchat\\agents\\_assistant_agent.py\", line 953, in on_messages_stream\n    async for inference_output in self._call_llm(\n    ...<15 lines>...\n            yield inference_output\n\n  File \"c:\\Users\\judirispah\\anaconda3\\envs\\agent\\Lib\\site-packages\\autogen_agentchat\\agents\\_assistant_agent.py\", line 1107, in _call_llm\n    model_result = await model_client.create(\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^\n    ...<4 lines>...\n    )\n    ^\n\n  File \"c:\\Users\\judirispah\\anaconda3\\envs\\agent\\Lib\\site-packages\\autogen_ext\\models\\openai\\_openai_client.py\", line 676, in create\n    result: Union[ParsedChatCompletion[BaseModel], ChatCompletion] = await future\n                                                                     ^^^^^^^^^^^^\n\n  File \"c:\\Users\\judirispah\\anaconda3\\envs\\agent\\Lib\\site-packages\\openai\\resources\\chat\\completions\\completions.py\", line 2028, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n    ...<45 lines>...\n    )\n    ^\n\n  File \"c:\\Users\\judirispah\\anaconda3\\envs\\agent\\Lib\\site-packages\\openai\\_base_client.py\", line 1748, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"c:\\Users\\judirispah\\anaconda3\\envs\\agent\\Lib\\site-packages\\openai\\_base_client.py\", line 1555, in request\n    raise self._make_status_error_from_response(err.response) from None\n\nopenai.RateLimitError: Error code: 429 - [{'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 10, model: gemini-2.5-flash\\nPlease retry in 28.261112209s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '10'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '28s'}]}}]\n"
     ]
    }
   ],
   "source": [
    "from autogen_agentchat.teams import RoundRobinGroupChat\n",
    "from autogen_agentchat.messages import TextMessage\n",
    "from autogen_agentchat.conditions import TextMentionTermination,MaxMessageTermination\n",
    "\n",
    "\n",
    "my_termination = TextMentionTermination(text='RUKJA')  | MaxMessageTermination(max_messages=2)\n",
    "\n",
    "team = RoundRobinGroupChat(\n",
    "    participants=[dsa_solver, code_reviewer, code_editor],\n",
    "    termination_condition=my_termination,\n",
    ")\n",
    "\n",
    "\n",
    "async def run_team():\n",
    "    task = TextMessage(content='write a code to add 2 numbers. TERMINATE',source='user')\n",
    "\n",
    "    result = await team.run(task=task)\n",
    "\n",
    "    for each_agent_message in result.messages:\n",
    "        print(f\"{each_agent_message.source} : {each_agent_message.content}\")\n",
    "\n",
    "\n",
    "    # print(result)\n",
    "\n",
    "await run_team()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "12ac0dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = await team.save_state()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "642d4741",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'type': 'TeamState',\n",
       " 'version': '1.0.0',\n",
       " 'agent_states': {'Complex_DSA_Solver': {'type': 'ChatAgentContainerState',\n",
       "   'version': '1.0.0',\n",
       "   'agent_state': {'type': 'AssistantAgentState',\n",
       "    'version': '1.0.0',\n",
       "    'llm_context': {'messages': [{'content': 'write a simple code in python to add 2 numbers',\n",
       "       'source': 'user',\n",
       "       'type': 'UserMessage'},\n",
       "      {'content': '```python\\ndef add_numbers(a, b):\\n  \"\"\"Adds two numbers.\"\"\"\\n  return a + b\\n```\\n',\n",
       "       'thought': None,\n",
       "       'source': 'Complex_DSA_Solver',\n",
       "       'type': 'AssistantMessage'},\n",
       "      {'content': 'write a simple code in python to add 2 numbers',\n",
       "       'source': 'user',\n",
       "       'type': 'UserMessage'},\n",
       "      {'content': '```python\\ndef add(x, y):\\n  \"\"\"Adds two numbers.\"\"\"\\n  return x + y\\n```\\n',\n",
       "       'thought': None,\n",
       "       'source': 'Complex_DSA_Solver',\n",
       "       'type': 'AssistantMessage'},\n",
       "      {'content': 'write a simple code in python to add 2 numbers',\n",
       "       'source': 'user',\n",
       "       'type': 'UserMessage'},\n",
       "      {'content': '```python\\ndef add(a, b):\\n  \"\"\"Adds two numbers.\"\"\"\\n  return a + b\\n```\\n',\n",
       "       'thought': None,\n",
       "       'source': 'Complex_DSA_Solver',\n",
       "       'type': 'AssistantMessage'},\n",
       "      {'content': 'TERMINATE\\n',\n",
       "       'source': 'CODE_REVIEWER',\n",
       "       'type': 'UserMessage'},\n",
       "      {'content': 'OK.\\n', 'source': 'CODE_EDITOR', 'type': 'UserMessage'},\n",
       "      {'content': 'Okay.\\n',\n",
       "       'thought': None,\n",
       "       'source': 'Complex_DSA_Solver',\n",
       "       'type': 'AssistantMessage'},\n",
       "      {'content': 'write a simple code in python to add 2 numbers',\n",
       "       'source': 'user',\n",
       "       'type': 'UserMessage'},\n",
       "      {'content': '```python\\ndef add_numbers(x, y):\\n  \"\"\"Adds two numbers.\"\"\"\\n  return x + y\\n```\\n',\n",
       "       'thought': None,\n",
       "       'source': 'Complex_DSA_Solver',\n",
       "       'type': 'AssistantMessage'},\n",
       "      {'content': 'write a code to find median of two sorted arrays',\n",
       "       'source': 'user',\n",
       "       'type': 'UserMessage'},\n",
       "      {'content': '```python\\nimport math\\n\\ndef findMedianSortedArrays(nums1, nums2):\\n    \"\"\"\\n    Finds the median of two sorted arrays.\\n\\n    Args:\\n        nums1: The first sorted array.\\n        nums2: The second sorted array.\\n\\n    Returns:\\n        The median of the combined sorted arrays.  Returns None if either input is invalid.\\n    \"\"\"\\n\\n    if not isinstance(nums1, list) or not isinstance(nums2, list):\\n        return None\\n    if not all(isinstance(num, (int, float)) for num in nums1) or not all(isinstance(num, (int, float)) for num in nums2):\\n        return None\\n\\n\\n    merged = sorted(nums1 + nums2)\\n    n = len(merged)\\n\\n    if n % 2 == 0:\\n        mid1 = merged[n // 2 - 1]\\n        mid2 = merged[n // 2]\\n        median = (mid1 + mid2) / 2\\n    else:\\n        median = merged[n // 2]\\n\\n    return median\\n```\\n\\n**Explanation and Improvements:**\\n\\n1. **Error Handling:** The code now includes checks to ensure that the inputs `nums1` and `nums2` are valid lists containing numbers.  This prevents common errors.  It returns `None` if the inputs are invalid.\\n\\n2. **Efficiency:** It directly merges the two lists and sorts them.  This avoids the more complex merging logic that is not needed for a direct calculation of the median.\\n\\n3. **Clarity:** The code is more clearly structured and includes a docstring to explain its purpose and arguments.\\n\\n**Example Usage:**\\n\\n```python\\narr1 = [1, 3]\\narr2 = [2]\\nmedian = findMedianSortedArrays(arr1, arr2)\\nprint(f\"Median: {median}\")  # Output: Median: 2.0\\n\\narr3 = [1, 2]\\narr4 = [3, 4]\\nmedian = findMedianSortedArrays(arr3, arr4)\\nprint(f\"Median: {median}\")  # Output: Median: 2.5\\n\\narr5 = [1, 3, 5]\\narr6 = [2, 4, 6]\\nmedian = findMedianSortedArrays(arr5, arr6)\\nprint(f\"Median: {median}\")  # Output: Median: 3.0\\n\\n\\n# Example of invalid input\\ninvalid_input1 = [1, 2, \"a\"]\\ninvalid_input2 = [3, 4]\\nmedian = findMedianSortedArrays(invalid_input1, invalid_input2)\\nprint(f\"Median: {median}\")  # Output: Median: None\\n```\\n\\nThis improved solution is more robust and efficient for finding the median of two sorted arrays. Remember to handle potential errors and edge cases in real-world applications.\\n\\n\\n',\n",
       "       'thought': None,\n",
       "       'source': 'Complex_DSA_Solver',\n",
       "       'type': 'AssistantMessage'},\n",
       "      {'content': 'Write a simple Hello world code ?',\n",
       "       'source': 'user',\n",
       "       'type': 'UserMessage'},\n",
       "      {'content': '```python\\nprint(\"Hello, world!\")\\n```\\n',\n",
       "       'thought': None,\n",
       "       'source': 'Complex_DSA_Solver',\n",
       "       'type': 'AssistantMessage'},\n",
       "      {'content': 'write a code to add 2 numbers. TERMINATE',\n",
       "       'source': 'user',\n",
       "       'type': 'UserMessage'},\n",
       "      {'content': '```python\\ndef add(x, y):\\n  return x + y\\n```\\n',\n",
       "       'thought': None,\n",
       "       'source': 'Complex_DSA_Solver',\n",
       "       'type': 'AssistantMessage'}]}},\n",
       "   'message_buffer': []},\n",
       "  'CODE_REVIEWER': {'type': 'ChatAgentContainerState',\n",
       "   'version': '1.0.0',\n",
       "   'agent_state': {'type': 'AssistantAgentState',\n",
       "    'version': '1.0.0',\n",
       "    'llm_context': {'messages': [{'content': 'write a simple code in python to add 2 numbers',\n",
       "       'source': 'user',\n",
       "       'type': 'UserMessage'},\n",
       "      {'content': '```python\\ndef add_numbers(a, b):\\n  \"\"\"Adds two numbers.\"\"\"\\n  return a + b\\n```\\n',\n",
       "       'source': 'Complex_DSA_Solver',\n",
       "       'type': 'UserMessage'},\n",
       "      {'content': 'TERMINATE\\n',\n",
       "       'thought': None,\n",
       "       'source': 'CODE_REVIEWER',\n",
       "       'type': 'AssistantMessage'},\n",
       "      {'content': 'write a simple code in python to add 2 numbers',\n",
       "       'source': 'user',\n",
       "       'type': 'UserMessage'},\n",
       "      {'content': '```python\\ndef add(a, b):\\n  \"\"\"Adds two numbers.\"\"\"\\n  return a + b\\n```\\n',\n",
       "       'source': 'Complex_DSA_Solver',\n",
       "       'type': 'UserMessage'},\n",
       "      {'content': 'TERMINATE\\n',\n",
       "       'thought': None,\n",
       "       'source': 'CODE_REVIEWER',\n",
       "       'type': 'AssistantMessage'},\n",
       "      {'content': 'OK.\\n', 'source': 'CODE_EDITOR', 'type': 'UserMessage'},\n",
       "      {'content': 'Okay.\\n',\n",
       "       'source': 'Complex_DSA_Solver',\n",
       "       'type': 'UserMessage'},\n",
       "      {'content': 'Okay.\\n',\n",
       "       'thought': None,\n",
       "       'source': 'CODE_REVIEWER',\n",
       "       'type': 'AssistantMessage'},\n",
       "      {'content': 'write a simple code in python to add 2 numbers',\n",
       "       'source': 'user',\n",
       "       'type': 'UserMessage'},\n",
       "      {'content': '```python\\ndef add_numbers(x, y):\\n  \"\"\"Adds two numbers.\"\"\"\\n  return x + y\\n```\\n',\n",
       "       'source': 'Complex_DSA_Solver',\n",
       "       'type': 'UserMessage'},\n",
       "      {'content': 'TERMINATE\\n',\n",
       "       'thought': None,\n",
       "       'source': 'CODE_REVIEWER',\n",
       "       'type': 'AssistantMessage'}]}},\n",
       "   'message_buffer': [{'id': '400075bd-57c1-4bef-acca-93e2052923e7',\n",
       "     'source': 'user',\n",
       "     'models_usage': None,\n",
       "     'metadata': {},\n",
       "     'created_at': datetime.datetime(2025, 7, 31, 7, 8, 58, 739926, tzinfo=datetime.timezone.utc),\n",
       "     'content': 'write a code to add 2 numbers. TERMINATE',\n",
       "     'type': 'TextMessage'},\n",
       "    {'id': '4494dffd-543e-474a-bd23-9af2fe6d4086',\n",
       "     'source': 'Complex_DSA_Solver',\n",
       "     'models_usage': {'prompt_tokens': 855, 'completion_tokens': 19},\n",
       "     'metadata': {},\n",
       "     'created_at': datetime.datetime(2025, 7, 31, 7, 8, 59, 539187, tzinfo=datetime.timezone.utc),\n",
       "     'content': '```python\\ndef add(x, y):\\n  return x + y\\n```\\n',\n",
       "     'type': 'TextMessage'}]},\n",
       "  'CODE_EDITOR': {'type': 'ChatAgentContainerState',\n",
       "   'version': '1.0.0',\n",
       "   'agent_state': {'type': 'AssistantAgentState',\n",
       "    'version': '1.0.0',\n",
       "    'llm_context': {'messages': [{'content': 'write a simple code in python to add 2 numbers',\n",
       "       'source': 'user',\n",
       "       'type': 'UserMessage'},\n",
       "      {'content': '```python\\ndef add_numbers(a, b):\\n  \"\"\"Adds two numbers.\"\"\"\\n  return a + b\\n```\\n',\n",
       "       'source': 'Complex_DSA_Solver',\n",
       "       'type': 'UserMessage'},\n",
       "      {'content': 'TERMINATE\\n',\n",
       "       'source': 'CODE_REVIEWER',\n",
       "       'type': 'UserMessage'},\n",
       "      {'content': 'OK.\\n',\n",
       "       'thought': None,\n",
       "       'source': 'CODE_EDITOR',\n",
       "       'type': 'AssistantMessage'},\n",
       "      {'content': 'write a simple code in python to add 2 numbers',\n",
       "       'source': 'user',\n",
       "       'type': 'UserMessage'},\n",
       "      {'content': '```python\\ndef add(a, b):\\n  \"\"\"Adds two numbers.\"\"\"\\n  return a + b\\n```\\n',\n",
       "       'source': 'Complex_DSA_Solver',\n",
       "       'type': 'UserMessage'},\n",
       "      {'content': 'TERMINATE\\n',\n",
       "       'source': 'CODE_REVIEWER',\n",
       "       'type': 'UserMessage'},\n",
       "      {'content': 'OK.\\n',\n",
       "       'thought': None,\n",
       "       'source': 'CODE_EDITOR',\n",
       "       'type': 'AssistantMessage'},\n",
       "      {'content': 'Okay.\\n',\n",
       "       'source': 'Complex_DSA_Solver',\n",
       "       'type': 'UserMessage'},\n",
       "      {'content': 'Okay.\\n', 'source': 'CODE_REVIEWER', 'type': 'UserMessage'},\n",
       "      {'content': 'Okay.\\n',\n",
       "       'thought': None,\n",
       "       'source': 'CODE_EDITOR',\n",
       "       'type': 'AssistantMessage'}]}},\n",
       "   'message_buffer': [{'id': '400075bd-57c1-4bef-acca-93e2052923e7',\n",
       "     'source': 'user',\n",
       "     'models_usage': None,\n",
       "     'metadata': {},\n",
       "     'created_at': datetime.datetime(2025, 7, 31, 7, 8, 58, 739926, tzinfo=datetime.timezone.utc),\n",
       "     'content': 'write a code to add 2 numbers. TERMINATE',\n",
       "     'type': 'TextMessage'},\n",
       "    {'id': '4494dffd-543e-474a-bd23-9af2fe6d4086',\n",
       "     'source': 'Complex_DSA_Solver',\n",
       "     'models_usage': {'prompt_tokens': 855, 'completion_tokens': 19},\n",
       "     'metadata': {},\n",
       "     'created_at': datetime.datetime(2025, 7, 31, 7, 8, 59, 539187, tzinfo=datetime.timezone.utc),\n",
       "     'content': '```python\\ndef add(x, y):\\n  return x + y\\n```\\n',\n",
       "     'type': 'TextMessage'}]},\n",
       "  'RoundRobinGroupChatManager': {'type': 'RoundRobinManagerState',\n",
       "   'version': '1.0.0',\n",
       "   'message_thread': [{'id': '400075bd-57c1-4bef-acca-93e2052923e7',\n",
       "     'source': 'user',\n",
       "     'models_usage': None,\n",
       "     'metadata': {},\n",
       "     'created_at': datetime.datetime(2025, 7, 31, 7, 8, 58, 739926, tzinfo=datetime.timezone.utc),\n",
       "     'content': 'write a code to add 2 numbers. TERMINATE',\n",
       "     'type': 'TextMessage'},\n",
       "    {'id': '4494dffd-543e-474a-bd23-9af2fe6d4086',\n",
       "     'source': 'Complex_DSA_Solver',\n",
       "     'models_usage': {'prompt_tokens': 855, 'completion_tokens': 19},\n",
       "     'metadata': {},\n",
       "     'created_at': datetime.datetime(2025, 7, 31, 7, 8, 59, 539187, tzinfo=datetime.timezone.utc),\n",
       "     'content': '```python\\ndef add(x, y):\\n  return x + y\\n```\\n',\n",
       "     'type': 'TextMessage'}],\n",
       "   'current_turn': 0,\n",
       "   'next_speaker_index': 1}}}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f9ffe2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen_agentchat.agents import AssistantAgent\n",
    "add_1_agent_first = AssistantAgent(\n",
    "    name = 'add_1_agent_first',\n",
    "    model_client=model_client,\n",
    "    system_message=\"Add 1 to the number, first number is 0. Give result as output\"\n",
    ")\n",
    "\n",
    "add_1_agent_second = AssistantAgent(\n",
    "    name = 'add_1_agent_second',\n",
    "    model_client=model_client,\n",
    "    system_message=\"Add 1 to the number you got from previous run. Give result as output.\"\n",
    ")\n",
    " \n",
    "add_1_agent_third = AssistantAgent(\n",
    "    name = 'add_1_agent_third',\n",
    "    model_client=model_client,\n",
    "    system_message=\"Add 1 to the number from previous run. Give result as output.\"\n",
    ")\n",
    "\n",
    "my_increment_team = RoundRobinGroupChat(participants=[add_1_agent_first,add_1_agent_second,add_1_agent_third],max_turns=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aa02e1bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error processing publish message for add_1_agent_first_3b90d6bc-a39a-4edb-8505-1c418d9ffcce/3b90d6bc-a39a-4edb-8505-1c418d9ffcce\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\judirispah\\anaconda3\\envs\\agent\\Lib\\site-packages\\autogen_core\\_single_threaded_agent_runtime.py\", line 606, in _on_message\n",
      "    return await agent.on_message(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<2 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\judirispah\\anaconda3\\envs\\agent\\Lib\\site-packages\\autogen_core\\_base_agent.py\", line 119, in on_message\n",
      "    return await self.on_message_impl(message, ctx)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\judirispah\\anaconda3\\envs\\agent\\Lib\\site-packages\\autogen_agentchat\\teams\\_group_chat\\_sequential_routed_agent.py\", line 67, in on_message_impl\n",
      "    return await super().on_message_impl(message, ctx)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\judirispah\\anaconda3\\envs\\agent\\Lib\\site-packages\\autogen_core\\_routed_agent.py\", line 485, in on_message_impl\n",
      "    return await h(self, message, ctx)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\judirispah\\anaconda3\\envs\\agent\\Lib\\site-packages\\autogen_core\\_routed_agent.py\", line 268, in wrapper\n",
      "    return_value = await func(self, message, ctx)  # type: ignore\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\judirispah\\anaconda3\\envs\\agent\\Lib\\site-packages\\autogen_agentchat\\teams\\_group_chat\\_chat_agent_container.py\", line 84, in handle_request\n",
      "    async for msg in self._agent.on_messages_stream(self._message_buffer, ctx.cancellation_token):\n",
      "    ...<4 lines>...\n",
      "            await self._log_message(msg)\n",
      "  File \"c:\\Users\\judirispah\\anaconda3\\envs\\agent\\Lib\\site-packages\\autogen_agentchat\\agents\\_assistant_agent.py\", line 953, in on_messages_stream\n",
      "    async for inference_output in self._call_llm(\n",
      "    ...<15 lines>...\n",
      "            yield inference_output\n",
      "  File \"c:\\Users\\judirispah\\anaconda3\\envs\\agent\\Lib\\site-packages\\autogen_agentchat\\agents\\_assistant_agent.py\", line 1107, in _call_llm\n",
      "    model_result = await model_client.create(\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<4 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\judirispah\\anaconda3\\envs\\agent\\Lib\\site-packages\\autogen_ext\\models\\openai\\_openai_client.py\", line 676, in create\n",
      "    result: Union[ParsedChatCompletion[BaseModel], ChatCompletion] = await future\n",
      "                                                                     ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\judirispah\\anaconda3\\envs\\agent\\Lib\\site-packages\\openai\\resources\\chat\\completions\\completions.py\", line 2028, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "    ...<45 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\judirispah\\anaconda3\\envs\\agent\\Lib\\site-packages\\openai\\_base_client.py\", line 1748, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\judirispah\\anaconda3\\envs\\agent\\Lib\\site-packages\\openai\\_base_client.py\", line 1555, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - [{'error': {'code': 400, 'message': '* GenerateContentRequest.contents: contents is not specified\\n', 'status': 'INVALID_ARGUMENT'}}]\n",
      "Error processing publish message for add_1_agent_second_3b90d6bc-a39a-4edb-8505-1c418d9ffcce/3b90d6bc-a39a-4edb-8505-1c418d9ffcce\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\judirispah\\anaconda3\\envs\\agent\\Lib\\site-packages\\autogen_core\\_single_threaded_agent_runtime.py\", line 606, in _on_message\n",
      "    return await agent.on_message(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<2 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\judirispah\\anaconda3\\envs\\agent\\Lib\\site-packages\\autogen_core\\_base_agent.py\", line 119, in on_message\n",
      "    return await self.on_message_impl(message, ctx)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\judirispah\\anaconda3\\envs\\agent\\Lib\\site-packages\\autogen_agentchat\\teams\\_group_chat\\_sequential_routed_agent.py\", line 72, in on_message_impl\n",
      "    return await super().on_message_impl(message, ctx)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\judirispah\\anaconda3\\envs\\agent\\Lib\\site-packages\\autogen_core\\_routed_agent.py\", line 486, in on_message_impl\n",
      "    return await self.on_unhandled_message(message, ctx)  # type: ignore\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\judirispah\\anaconda3\\envs\\agent\\Lib\\site-packages\\autogen_agentchat\\teams\\_group_chat\\_chat_agent_container.py\", line 138, in on_unhandled_message\n",
      "    raise ValueError(f\"Unhandled message in agent container: {type(message)}\")\n",
      "ValueError: Unhandled message in agent container: <class 'autogen_agentchat.teams._group_chat._events.GroupChatError'>\n",
      "Error processing publish message for add_1_agent_third_3b90d6bc-a39a-4edb-8505-1c418d9ffcce/3b90d6bc-a39a-4edb-8505-1c418d9ffcce\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\judirispah\\anaconda3\\envs\\agent\\Lib\\site-packages\\autogen_core\\_single_threaded_agent_runtime.py\", line 606, in _on_message\n",
      "    return await agent.on_message(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<2 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\judirispah\\anaconda3\\envs\\agent\\Lib\\site-packages\\autogen_core\\_base_agent.py\", line 119, in on_message\n",
      "    return await self.on_message_impl(message, ctx)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\judirispah\\anaconda3\\envs\\agent\\Lib\\site-packages\\autogen_agentchat\\teams\\_group_chat\\_sequential_routed_agent.py\", line 72, in on_message_impl\n",
      "    return await super().on_message_impl(message, ctx)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\judirispah\\anaconda3\\envs\\agent\\Lib\\site-packages\\autogen_core\\_routed_agent.py\", line 486, in on_message_impl\n",
      "    return await self.on_unhandled_message(message, ctx)  # type: ignore\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\judirispah\\anaconda3\\envs\\agent\\Lib\\site-packages\\autogen_agentchat\\teams\\_group_chat\\_chat_agent_container.py\", line 138, in on_unhandled_message\n",
      "    raise ValueError(f\"Unhandled message in agent container: {type(message)}\")\n",
      "ValueError: Unhandled message in agent container: <class 'autogen_agentchat.teams._group_chat._events.GroupChatError'>\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "BadRequestError: Error code: 400 - [{'error': {'code': 400, 'message': '* GenerateContentRequest.contents: contents is not specified\\n', 'status': 'INVALID_ARGUMENT'}}]\nTraceback:\nTraceback (most recent call last):\n\n  File \"c:\\Users\\judirispah\\anaconda3\\envs\\agent\\Lib\\site-packages\\autogen_agentchat\\teams\\_group_chat\\_chat_agent_container.py\", line 84, in handle_request\n    async for msg in self._agent.on_messages_stream(self._message_buffer, ctx.cancellation_token):\n    ...<4 lines>...\n            await self._log_message(msg)\n\n  File \"c:\\Users\\judirispah\\anaconda3\\envs\\agent\\Lib\\site-packages\\autogen_agentchat\\agents\\_assistant_agent.py\", line 953, in on_messages_stream\n    async for inference_output in self._call_llm(\n    ...<15 lines>...\n            yield inference_output\n\n  File \"c:\\Users\\judirispah\\anaconda3\\envs\\agent\\Lib\\site-packages\\autogen_agentchat\\agents\\_assistant_agent.py\", line 1107, in _call_llm\n    model_result = await model_client.create(\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^\n    ...<4 lines>...\n    )\n    ^\n\n  File \"c:\\Users\\judirispah\\anaconda3\\envs\\agent\\Lib\\site-packages\\autogen_ext\\models\\openai\\_openai_client.py\", line 676, in create\n    result: Union[ParsedChatCompletion[BaseModel], ChatCompletion] = await future\n                                                                     ^^^^^^^^^^^^\n\n  File \"c:\\Users\\judirispah\\anaconda3\\envs\\agent\\Lib\\site-packages\\openai\\resources\\chat\\completions\\completions.py\", line 2028, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n    ...<45 lines>...\n    )\n    ^\n\n  File \"c:\\Users\\judirispah\\anaconda3\\envs\\agent\\Lib\\site-packages\\openai\\_base_client.py\", line 1748, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"c:\\Users\\judirispah\\anaconda3\\envs\\agent\\Lib\\site-packages\\openai\\_base_client.py\", line 1555, in request\n    raise self._make_status_error_from_response(err.response) from None\n\nopenai.BadRequestError: Error code: 400 - [{'error': {'code': 400, 'message': '* GenerateContentRequest.contents: contents is not specified\\n', 'status': 'INVALID_ARGUMENT'}}]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mautogen_agentchat\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mui\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Console\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m Console(my_increment_team.run_stream())\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\judirispah\\anaconda3\\envs\\agent\\Lib\\site-packages\\autogen_agentchat\\ui\\_console.py:117\u001b[39m, in \u001b[36mConsole\u001b[39m\u001b[34m(stream, no_inline_images, output_stats, user_input_manager)\u001b[39m\n\u001b[32m    113\u001b[39m last_processed: Optional[T] = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    115\u001b[39m streaming_chunks: List[\u001b[38;5;28mstr\u001b[39m] = []\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m message \u001b[38;5;129;01min\u001b[39;00m stream:\n\u001b[32m    118\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(message, TaskResult):\n\u001b[32m    119\u001b[39m         duration = time.time() - start_time\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\judirispah\\anaconda3\\envs\\agent\\Lib\\site-packages\\autogen_agentchat\\teams\\_group_chat\\_base_group_chat.py:522\u001b[39m, in \u001b[36mBaseGroupChat.run_stream\u001b[39m\u001b[34m(self, task, cancellation_token, output_task_messages)\u001b[39m\n\u001b[32m    518\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(message, GroupChatTermination):\n\u001b[32m    519\u001b[39m     \u001b[38;5;66;03m# If the message contains an error, we need to raise it here.\u001b[39;00m\n\u001b[32m    520\u001b[39m     \u001b[38;5;66;03m# This will stop the team and propagate the error.\u001b[39;00m\n\u001b[32m    521\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m message.error \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m522\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;28mstr\u001b[39m(message.error))\n\u001b[32m    523\u001b[39m     stop_reason = message.message.content\n\u001b[32m    524\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[31mRuntimeError\u001b[39m: BadRequestError: Error code: 400 - [{'error': {'code': 400, 'message': '* GenerateContentRequest.contents: contents is not specified\\n', 'status': 'INVALID_ARGUMENT'}}]\nTraceback:\nTraceback (most recent call last):\n\n  File \"c:\\Users\\judirispah\\anaconda3\\envs\\agent\\Lib\\site-packages\\autogen_agentchat\\teams\\_group_chat\\_chat_agent_container.py\", line 84, in handle_request\n    async for msg in self._agent.on_messages_stream(self._message_buffer, ctx.cancellation_token):\n    ...<4 lines>...\n            await self._log_message(msg)\n\n  File \"c:\\Users\\judirispah\\anaconda3\\envs\\agent\\Lib\\site-packages\\autogen_agentchat\\agents\\_assistant_agent.py\", line 953, in on_messages_stream\n    async for inference_output in self._call_llm(\n    ...<15 lines>...\n            yield inference_output\n\n  File \"c:\\Users\\judirispah\\anaconda3\\envs\\agent\\Lib\\site-packages\\autogen_agentchat\\agents\\_assistant_agent.py\", line 1107, in _call_llm\n    model_result = await model_client.create(\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^\n    ...<4 lines>...\n    )\n    ^\n\n  File \"c:\\Users\\judirispah\\anaconda3\\envs\\agent\\Lib\\site-packages\\autogen_ext\\models\\openai\\_openai_client.py\", line 676, in create\n    result: Union[ParsedChatCompletion[BaseModel], ChatCompletion] = await future\n                                                                     ^^^^^^^^^^^^\n\n  File \"c:\\Users\\judirispah\\anaconda3\\envs\\agent\\Lib\\site-packages\\openai\\resources\\chat\\completions\\completions.py\", line 2028, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n    ...<45 lines>...\n    )\n    ^\n\n  File \"c:\\Users\\judirispah\\anaconda3\\envs\\agent\\Lib\\site-packages\\openai\\_base_client.py\", line 1748, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"c:\\Users\\judirispah\\anaconda3\\envs\\agent\\Lib\\site-packages\\openai\\_base_client.py\", line 1555, in request\n    raise self._make_status_error_from_response(err.response) from None\n\nopenai.BadRequestError: Error code: 400 - [{'error': {'code': 400, 'message': '* GenerateContentRequest.contents: contents is not specified\\n', 'status': 'INVALID_ARGUMENT'}}]\n"
     ]
    }
   ],
   "source": [
    "from autogen_agentchat.ui import Console\n",
    "\n",
    "await Console(my_increment_team.run_stream())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "50900962",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error processing publish message for add_1_agent_third_3332409a-ef77-4396-be4b-d82ea1b8bcd1/3332409a-ef77-4396-be4b-d82ea1b8bcd1\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\judirispah\\anaconda3\\envs\\agent\\Lib\\site-packages\\autogen_core\\_single_threaded_agent_runtime.py\", line 606, in _on_message\n",
      "    return await agent.on_message(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<2 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\judirispah\\anaconda3\\envs\\agent\\Lib\\site-packages\\autogen_core\\_base_agent.py\", line 119, in on_message\n",
      "    return await self.on_message_impl(message, ctx)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\judirispah\\anaconda3\\envs\\agent\\Lib\\site-packages\\autogen_agentchat\\teams\\_group_chat\\_sequential_routed_agent.py\", line 67, in on_message_impl\n",
      "    return await super().on_message_impl(message, ctx)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\judirispah\\anaconda3\\envs\\agent\\Lib\\site-packages\\autogen_core\\_routed_agent.py\", line 485, in on_message_impl\n",
      "    return await h(self, message, ctx)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\judirispah\\anaconda3\\envs\\agent\\Lib\\site-packages\\autogen_core\\_routed_agent.py\", line 268, in wrapper\n",
      "    return_value = await func(self, message, ctx)  # type: ignore\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\judirispah\\anaconda3\\envs\\agent\\Lib\\site-packages\\autogen_agentchat\\teams\\_group_chat\\_chat_agent_container.py\", line 84, in handle_request\n",
      "    async for msg in self._agent.on_messages_stream(self._message_buffer, ctx.cancellation_token):\n",
      "    ...<4 lines>...\n",
      "            await self._log_message(msg)\n",
      "  File \"c:\\Users\\judirispah\\anaconda3\\envs\\agent\\Lib\\site-packages\\autogen_agentchat\\agents\\_assistant_agent.py\", line 953, in on_messages_stream\n",
      "    async for inference_output in self._call_llm(\n",
      "    ...<15 lines>...\n",
      "            yield inference_output\n",
      "  File \"c:\\Users\\judirispah\\anaconda3\\envs\\agent\\Lib\\site-packages\\autogen_agentchat\\agents\\_assistant_agent.py\", line 1107, in _call_llm\n",
      "    model_result = await model_client.create(\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<4 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\judirispah\\anaconda3\\envs\\agent\\Lib\\site-packages\\autogen_ext\\models\\openai\\_openai_client.py\", line 676, in create\n",
      "    result: Union[ParsedChatCompletion[BaseModel], ChatCompletion] = await future\n",
      "                                                                     ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\judirispah\\anaconda3\\envs\\agent\\Lib\\site-packages\\openai\\resources\\chat\\completions\\completions.py\", line 2028, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "    ...<45 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\judirispah\\anaconda3\\envs\\agent\\Lib\\site-packages\\openai\\_base_client.py\", line 1748, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\judirispah\\anaconda3\\envs\\agent\\Lib\\site-packages\\openai\\_base_client.py\", line 1555, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - [{'error': {'code': 400, 'message': '* GenerateContentRequest.contents: contents is not specified\\n', 'status': 'INVALID_ARGUMENT'}}]\n",
      "Error processing publish message for add_1_agent_first_3332409a-ef77-4396-be4b-d82ea1b8bcd1/3332409a-ef77-4396-be4b-d82ea1b8bcd1\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\judirispah\\anaconda3\\envs\\agent\\Lib\\site-packages\\autogen_core\\_single_threaded_agent_runtime.py\", line 606, in _on_message\n",
      "    return await agent.on_message(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<2 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\judirispah\\anaconda3\\envs\\agent\\Lib\\site-packages\\autogen_core\\_base_agent.py\", line 119, in on_message\n",
      "    return await self.on_message_impl(message, ctx)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\judirispah\\anaconda3\\envs\\agent\\Lib\\site-packages\\autogen_agentchat\\teams\\_group_chat\\_sequential_routed_agent.py\", line 72, in on_message_impl\n",
      "    return await super().on_message_impl(message, ctx)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\judirispah\\anaconda3\\envs\\agent\\Lib\\site-packages\\autogen_core\\_routed_agent.py\", line 486, in on_message_impl\n",
      "    return await self.on_unhandled_message(message, ctx)  # type: ignore\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\judirispah\\anaconda3\\envs\\agent\\Lib\\site-packages\\autogen_agentchat\\teams\\_group_chat\\_chat_agent_container.py\", line 138, in on_unhandled_message\n",
      "    raise ValueError(f\"Unhandled message in agent container: {type(message)}\")\n",
      "ValueError: Unhandled message in agent container: <class 'autogen_agentchat.teams._group_chat._events.GroupChatError'>\n",
      "Error processing publish message for add_1_agent_second_3332409a-ef77-4396-be4b-d82ea1b8bcd1/3332409a-ef77-4396-be4b-d82ea1b8bcd1\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\judirispah\\anaconda3\\envs\\agent\\Lib\\site-packages\\autogen_core\\_single_threaded_agent_runtime.py\", line 606, in _on_message\n",
      "    return await agent.on_message(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<2 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\judirispah\\anaconda3\\envs\\agent\\Lib\\site-packages\\autogen_core\\_base_agent.py\", line 119, in on_message\n",
      "    return await self.on_message_impl(message, ctx)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\judirispah\\anaconda3\\envs\\agent\\Lib\\site-packages\\autogen_agentchat\\teams\\_group_chat\\_sequential_routed_agent.py\", line 72, in on_message_impl\n",
      "    return await super().on_message_impl(message, ctx)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\judirispah\\anaconda3\\envs\\agent\\Lib\\site-packages\\autogen_core\\_routed_agent.py\", line 486, in on_message_impl\n",
      "    return await self.on_unhandled_message(message, ctx)  # type: ignore\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\judirispah\\anaconda3\\envs\\agent\\Lib\\site-packages\\autogen_agentchat\\teams\\_group_chat\\_chat_agent_container.py\", line 138, in on_unhandled_message\n",
      "    raise ValueError(f\"Unhandled message in agent container: {type(message)}\")\n",
      "ValueError: Unhandled message in agent container: <class 'autogen_agentchat.teams._group_chat._events.GroupChatError'>\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "BadRequestError: Error code: 400 - [{'error': {'code': 400, 'message': '* GenerateContentRequest.contents: contents is not specified\\n', 'status': 'INVALID_ARGUMENT'}}]\nTraceback:\nTraceback (most recent call last):\n\n  File \"c:\\Users\\judirispah\\anaconda3\\envs\\agent\\Lib\\site-packages\\autogen_agentchat\\teams\\_group_chat\\_chat_agent_container.py\", line 84, in handle_request\n    async for msg in self._agent.on_messages_stream(self._message_buffer, ctx.cancellation_token):\n    ...<4 lines>...\n            await self._log_message(msg)\n\n  File \"c:\\Users\\judirispah\\anaconda3\\envs\\agent\\Lib\\site-packages\\autogen_agentchat\\agents\\_assistant_agent.py\", line 953, in on_messages_stream\n    async for inference_output in self._call_llm(\n    ...<15 lines>...\n            yield inference_output\n\n  File \"c:\\Users\\judirispah\\anaconda3\\envs\\agent\\Lib\\site-packages\\autogen_agentchat\\agents\\_assistant_agent.py\", line 1107, in _call_llm\n    model_result = await model_client.create(\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^\n    ...<4 lines>...\n    )\n    ^\n\n  File \"c:\\Users\\judirispah\\anaconda3\\envs\\agent\\Lib\\site-packages\\autogen_ext\\models\\openai\\_openai_client.py\", line 676, in create\n    result: Union[ParsedChatCompletion[BaseModel], ChatCompletion] = await future\n                                                                     ^^^^^^^^^^^^\n\n  File \"c:\\Users\\judirispah\\anaconda3\\envs\\agent\\Lib\\site-packages\\openai\\resources\\chat\\completions\\completions.py\", line 2028, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n    ...<45 lines>...\n    )\n    ^\n\n  File \"c:\\Users\\judirispah\\anaconda3\\envs\\agent\\Lib\\site-packages\\openai\\_base_client.py\", line 1748, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"c:\\Users\\judirispah\\anaconda3\\envs\\agent\\Lib\\site-packages\\openai\\_base_client.py\", line 1555, in request\n    raise self._make_status_error_from_response(err.response) from None\n\nopenai.BadRequestError: Error code: 400 - [{'error': {'code': 400, 'message': '* GenerateContentRequest.contents: contents is not specified\\n', 'status': 'INVALID_ARGUMENT'}}]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m Console(my_increment_team.run_stream())\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\judirispah\\anaconda3\\envs\\agent\\Lib\\site-packages\\autogen_agentchat\\ui\\_console.py:117\u001b[39m, in \u001b[36mConsole\u001b[39m\u001b[34m(stream, no_inline_images, output_stats, user_input_manager)\u001b[39m\n\u001b[32m    113\u001b[39m last_processed: Optional[T] = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    115\u001b[39m streaming_chunks: List[\u001b[38;5;28mstr\u001b[39m] = []\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m message \u001b[38;5;129;01min\u001b[39;00m stream:\n\u001b[32m    118\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(message, TaskResult):\n\u001b[32m    119\u001b[39m         duration = time.time() - start_time\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\judirispah\\anaconda3\\envs\\agent\\Lib\\site-packages\\autogen_agentchat\\teams\\_group_chat\\_base_group_chat.py:522\u001b[39m, in \u001b[36mBaseGroupChat.run_stream\u001b[39m\u001b[34m(self, task, cancellation_token, output_task_messages)\u001b[39m\n\u001b[32m    518\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(message, GroupChatTermination):\n\u001b[32m    519\u001b[39m     \u001b[38;5;66;03m# If the message contains an error, we need to raise it here.\u001b[39;00m\n\u001b[32m    520\u001b[39m     \u001b[38;5;66;03m# This will stop the team and propagate the error.\u001b[39;00m\n\u001b[32m    521\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m message.error \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m522\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;28mstr\u001b[39m(message.error))\n\u001b[32m    523\u001b[39m     stop_reason = message.message.content\n\u001b[32m    524\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[31mRuntimeError\u001b[39m: BadRequestError: Error code: 400 - [{'error': {'code': 400, 'message': '* GenerateContentRequest.contents: contents is not specified\\n', 'status': 'INVALID_ARGUMENT'}}]\nTraceback:\nTraceback (most recent call last):\n\n  File \"c:\\Users\\judirispah\\anaconda3\\envs\\agent\\Lib\\site-packages\\autogen_agentchat\\teams\\_group_chat\\_chat_agent_container.py\", line 84, in handle_request\n    async for msg in self._agent.on_messages_stream(self._message_buffer, ctx.cancellation_token):\n    ...<4 lines>...\n            await self._log_message(msg)\n\n  File \"c:\\Users\\judirispah\\anaconda3\\envs\\agent\\Lib\\site-packages\\autogen_agentchat\\agents\\_assistant_agent.py\", line 953, in on_messages_stream\n    async for inference_output in self._call_llm(\n    ...<15 lines>...\n            yield inference_output\n\n  File \"c:\\Users\\judirispah\\anaconda3\\envs\\agent\\Lib\\site-packages\\autogen_agentchat\\agents\\_assistant_agent.py\", line 1107, in _call_llm\n    model_result = await model_client.create(\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^\n    ...<4 lines>...\n    )\n    ^\n\n  File \"c:\\Users\\judirispah\\anaconda3\\envs\\agent\\Lib\\site-packages\\autogen_ext\\models\\openai\\_openai_client.py\", line 676, in create\n    result: Union[ParsedChatCompletion[BaseModel], ChatCompletion] = await future\n                                                                     ^^^^^^^^^^^^\n\n  File \"c:\\Users\\judirispah\\anaconda3\\envs\\agent\\Lib\\site-packages\\openai\\resources\\chat\\completions\\completions.py\", line 2028, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n    ...<45 lines>...\n    )\n    ^\n\n  File \"c:\\Users\\judirispah\\anaconda3\\envs\\agent\\Lib\\site-packages\\openai\\_base_client.py\", line 1748, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"c:\\Users\\judirispah\\anaconda3\\envs\\agent\\Lib\\site-packages\\openai\\_base_client.py\", line 1555, in request\n    raise self._make_status_error_from_response(err.response) from None\n\nopenai.BadRequestError: Error code: 400 - [{'error': {'code': 400, 'message': '* GenerateContentRequest.contents: contents is not specified\\n', 'status': 'INVALID_ARGUMENT'}}]\n"
     ]
    }
   ],
   "source": [
    "await Console(my_increment_team.run_stream())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "af6a9181",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error processing publish message for add_1_agent_first_3332409a-ef77-4396-be4b-d82ea1b8bcd1/3332409a-ef77-4396-be4b-d82ea1b8bcd1\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\judirispah\\anaconda3\\envs\\agent\\Lib\\site-packages\\autogen_core\\_single_threaded_agent_runtime.py\", line 606, in _on_message\n",
      "    return await agent.on_message(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<2 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\judirispah\\anaconda3\\envs\\agent\\Lib\\site-packages\\autogen_core\\_base_agent.py\", line 119, in on_message\n",
      "    return await self.on_message_impl(message, ctx)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\judirispah\\anaconda3\\envs\\agent\\Lib\\site-packages\\autogen_agentchat\\teams\\_group_chat\\_sequential_routed_agent.py\", line 67, in on_message_impl\n",
      "    return await super().on_message_impl(message, ctx)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\judirispah\\anaconda3\\envs\\agent\\Lib\\site-packages\\autogen_core\\_routed_agent.py\", line 485, in on_message_impl\n",
      "    return await h(self, message, ctx)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\judirispah\\anaconda3\\envs\\agent\\Lib\\site-packages\\autogen_core\\_routed_agent.py\", line 268, in wrapper\n",
      "    return_value = await func(self, message, ctx)  # type: ignore\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\judirispah\\anaconda3\\envs\\agent\\Lib\\site-packages\\autogen_agentchat\\teams\\_group_chat\\_chat_agent_container.py\", line 84, in handle_request\n",
      "    async for msg in self._agent.on_messages_stream(self._message_buffer, ctx.cancellation_token):\n",
      "    ...<4 lines>...\n",
      "            await self._log_message(msg)\n",
      "  File \"c:\\Users\\judirispah\\anaconda3\\envs\\agent\\Lib\\site-packages\\autogen_agentchat\\agents\\_assistant_agent.py\", line 953, in on_messages_stream\n",
      "    async for inference_output in self._call_llm(\n",
      "    ...<15 lines>...\n",
      "            yield inference_output\n",
      "  File \"c:\\Users\\judirispah\\anaconda3\\envs\\agent\\Lib\\site-packages\\autogen_agentchat\\agents\\_assistant_agent.py\", line 1107, in _call_llm\n",
      "    model_result = await model_client.create(\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<4 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\judirispah\\anaconda3\\envs\\agent\\Lib\\site-packages\\autogen_ext\\models\\openai\\_openai_client.py\", line 676, in create\n",
      "    result: Union[ParsedChatCompletion[BaseModel], ChatCompletion] = await future\n",
      "                                                                     ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\judirispah\\anaconda3\\envs\\agent\\Lib\\site-packages\\openai\\resources\\chat\\completions\\completions.py\", line 2028, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "    ...<45 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\judirispah\\anaconda3\\envs\\agent\\Lib\\site-packages\\openai\\_base_client.py\", line 1748, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\judirispah\\anaconda3\\envs\\agent\\Lib\\site-packages\\openai\\_base_client.py\", line 1555, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - [{'error': {'code': 400, 'message': '* GenerateContentRequest.contents: contents is not specified\\n', 'status': 'INVALID_ARGUMENT'}}]\n",
      "Error processing publish message for add_1_agent_second_3332409a-ef77-4396-be4b-d82ea1b8bcd1/3332409a-ef77-4396-be4b-d82ea1b8bcd1\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\judirispah\\anaconda3\\envs\\agent\\Lib\\site-packages\\autogen_core\\_single_threaded_agent_runtime.py\", line 606, in _on_message\n",
      "    return await agent.on_message(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<2 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\judirispah\\anaconda3\\envs\\agent\\Lib\\site-packages\\autogen_core\\_base_agent.py\", line 119, in on_message\n",
      "    return await self.on_message_impl(message, ctx)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\judirispah\\anaconda3\\envs\\agent\\Lib\\site-packages\\autogen_agentchat\\teams\\_group_chat\\_sequential_routed_agent.py\", line 72, in on_message_impl\n",
      "    return await super().on_message_impl(message, ctx)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\judirispah\\anaconda3\\envs\\agent\\Lib\\site-packages\\autogen_core\\_routed_agent.py\", line 486, in on_message_impl\n",
      "    return await self.on_unhandled_message(message, ctx)  # type: ignore\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\judirispah\\anaconda3\\envs\\agent\\Lib\\site-packages\\autogen_agentchat\\teams\\_group_chat\\_chat_agent_container.py\", line 138, in on_unhandled_message\n",
      "    raise ValueError(f\"Unhandled message in agent container: {type(message)}\")\n",
      "ValueError: Unhandled message in agent container: <class 'autogen_agentchat.teams._group_chat._events.GroupChatError'>\n",
      "Error processing publish message for add_1_agent_third_3332409a-ef77-4396-be4b-d82ea1b8bcd1/3332409a-ef77-4396-be4b-d82ea1b8bcd1\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\judirispah\\anaconda3\\envs\\agent\\Lib\\site-packages\\autogen_core\\_single_threaded_agent_runtime.py\", line 606, in _on_message\n",
      "    return await agent.on_message(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<2 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\judirispah\\anaconda3\\envs\\agent\\Lib\\site-packages\\autogen_core\\_base_agent.py\", line 119, in on_message\n",
      "    return await self.on_message_impl(message, ctx)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\judirispah\\anaconda3\\envs\\agent\\Lib\\site-packages\\autogen_agentchat\\teams\\_group_chat\\_sequential_routed_agent.py\", line 72, in on_message_impl\n",
      "    return await super().on_message_impl(message, ctx)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\judirispah\\anaconda3\\envs\\agent\\Lib\\site-packages\\autogen_core\\_routed_agent.py\", line 486, in on_message_impl\n",
      "    return await self.on_unhandled_message(message, ctx)  # type: ignore\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\judirispah\\anaconda3\\envs\\agent\\Lib\\site-packages\\autogen_agentchat\\teams\\_group_chat\\_chat_agent_container.py\", line 138, in on_unhandled_message\n",
      "    raise ValueError(f\"Unhandled message in agent container: {type(message)}\")\n",
      "ValueError: Unhandled message in agent container: <class 'autogen_agentchat.teams._group_chat._events.GroupChatError'>\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "BadRequestError: Error code: 400 - [{'error': {'code': 400, 'message': '* GenerateContentRequest.contents: contents is not specified\\n', 'status': 'INVALID_ARGUMENT'}}]\nTraceback:\nTraceback (most recent call last):\n\n  File \"c:\\Users\\judirispah\\anaconda3\\envs\\agent\\Lib\\site-packages\\autogen_agentchat\\teams\\_group_chat\\_chat_agent_container.py\", line 84, in handle_request\n    async for msg in self._agent.on_messages_stream(self._message_buffer, ctx.cancellation_token):\n    ...<4 lines>...\n            await self._log_message(msg)\n\n  File \"c:\\Users\\judirispah\\anaconda3\\envs\\agent\\Lib\\site-packages\\autogen_agentchat\\agents\\_assistant_agent.py\", line 953, in on_messages_stream\n    async for inference_output in self._call_llm(\n    ...<15 lines>...\n            yield inference_output\n\n  File \"c:\\Users\\judirispah\\anaconda3\\envs\\agent\\Lib\\site-packages\\autogen_agentchat\\agents\\_assistant_agent.py\", line 1107, in _call_llm\n    model_result = await model_client.create(\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^\n    ...<4 lines>...\n    )\n    ^\n\n  File \"c:\\Users\\judirispah\\anaconda3\\envs\\agent\\Lib\\site-packages\\autogen_ext\\models\\openai\\_openai_client.py\", line 676, in create\n    result: Union[ParsedChatCompletion[BaseModel], ChatCompletion] = await future\n                                                                     ^^^^^^^^^^^^\n\n  File \"c:\\Users\\judirispah\\anaconda3\\envs\\agent\\Lib\\site-packages\\openai\\resources\\chat\\completions\\completions.py\", line 2028, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n    ...<45 lines>...\n    )\n    ^\n\n  File \"c:\\Users\\judirispah\\anaconda3\\envs\\agent\\Lib\\site-packages\\openai\\_base_client.py\", line 1748, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"c:\\Users\\judirispah\\anaconda3\\envs\\agent\\Lib\\site-packages\\openai\\_base_client.py\", line 1555, in request\n    raise self._make_status_error_from_response(err.response) from None\n\nopenai.BadRequestError: Error code: 400 - [{'error': {'code': 400, 'message': '* GenerateContentRequest.contents: contents is not specified\\n', 'status': 'INVALID_ARGUMENT'}}]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m Console(my_increment_team.run_stream())\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\judirispah\\anaconda3\\envs\\agent\\Lib\\site-packages\\autogen_agentchat\\ui\\_console.py:117\u001b[39m, in \u001b[36mConsole\u001b[39m\u001b[34m(stream, no_inline_images, output_stats, user_input_manager)\u001b[39m\n\u001b[32m    113\u001b[39m last_processed: Optional[T] = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    115\u001b[39m streaming_chunks: List[\u001b[38;5;28mstr\u001b[39m] = []\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m message \u001b[38;5;129;01min\u001b[39;00m stream:\n\u001b[32m    118\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(message, TaskResult):\n\u001b[32m    119\u001b[39m         duration = time.time() - start_time\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\judirispah\\anaconda3\\envs\\agent\\Lib\\site-packages\\autogen_agentchat\\teams\\_group_chat\\_base_group_chat.py:522\u001b[39m, in \u001b[36mBaseGroupChat.run_stream\u001b[39m\u001b[34m(self, task, cancellation_token, output_task_messages)\u001b[39m\n\u001b[32m    518\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(message, GroupChatTermination):\n\u001b[32m    519\u001b[39m     \u001b[38;5;66;03m# If the message contains an error, we need to raise it here.\u001b[39;00m\n\u001b[32m    520\u001b[39m     \u001b[38;5;66;03m# This will stop the team and propagate the error.\u001b[39;00m\n\u001b[32m    521\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m message.error \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m522\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;28mstr\u001b[39m(message.error))\n\u001b[32m    523\u001b[39m     stop_reason = message.message.content\n\u001b[32m    524\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[31mRuntimeError\u001b[39m: BadRequestError: Error code: 400 - [{'error': {'code': 400, 'message': '* GenerateContentRequest.contents: contents is not specified\\n', 'status': 'INVALID_ARGUMENT'}}]\nTraceback:\nTraceback (most recent call last):\n\n  File \"c:\\Users\\judirispah\\anaconda3\\envs\\agent\\Lib\\site-packages\\autogen_agentchat\\teams\\_group_chat\\_chat_agent_container.py\", line 84, in handle_request\n    async for msg in self._agent.on_messages_stream(self._message_buffer, ctx.cancellation_token):\n    ...<4 lines>...\n            await self._log_message(msg)\n\n  File \"c:\\Users\\judirispah\\anaconda3\\envs\\agent\\Lib\\site-packages\\autogen_agentchat\\agents\\_assistant_agent.py\", line 953, in on_messages_stream\n    async for inference_output in self._call_llm(\n    ...<15 lines>...\n            yield inference_output\n\n  File \"c:\\Users\\judirispah\\anaconda3\\envs\\agent\\Lib\\site-packages\\autogen_agentchat\\agents\\_assistant_agent.py\", line 1107, in _call_llm\n    model_result = await model_client.create(\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^\n    ...<4 lines>...\n    )\n    ^\n\n  File \"c:\\Users\\judirispah\\anaconda3\\envs\\agent\\Lib\\site-packages\\autogen_ext\\models\\openai\\_openai_client.py\", line 676, in create\n    result: Union[ParsedChatCompletion[BaseModel], ChatCompletion] = await future\n                                                                     ^^^^^^^^^^^^\n\n  File \"c:\\Users\\judirispah\\anaconda3\\envs\\agent\\Lib\\site-packages\\openai\\resources\\chat\\completions\\completions.py\", line 2028, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n    ...<45 lines>...\n    )\n    ^\n\n  File \"c:\\Users\\judirispah\\anaconda3\\envs\\agent\\Lib\\site-packages\\openai\\_base_client.py\", line 1748, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"c:\\Users\\judirispah\\anaconda3\\envs\\agent\\Lib\\site-packages\\openai\\_base_client.py\", line 1555, in request\n    raise self._make_status_error_from_response(err.response) from None\n\nopenai.BadRequestError: Error code: 400 - [{'error': {'code': 400, 'message': '* GenerateContentRequest.contents: contents is not specified\\n', 'status': 'INVALID_ARGUMENT'}}]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "await Console(my_increment_team.run_stream())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44150aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "team.reset()\n",
    "await Console(my_increment_team.run_stream())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8fe2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "await my_increment_team.reset()\n",
    "await Console(my_increment_team.run_stream())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4765963",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "my_increment_team = RoundRobinGroupChat(participants=[add_1_agent_first],max_turns=5)\n",
    "await my_increment_team.reset()\n",
    "await Console(my_increment_team.run_stream())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f1f147a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Task was cancelled.\n"
     ]
    }
   ],
   "source": [
    "from autogen_core import CancellationToken\n",
    "\n",
    "\n",
    "# Create a cancellation token.\n",
    "cancellation_token = CancellationToken()\n",
    "\n",
    "# Use another coroutine to run the team.\n",
    "run = asyncio.create_task(\n",
    "    team.run(\n",
    "        task=\"Translate the poem to Spanish.\",\n",
    "        cancellation_token=cancellation_token,\n",
    "    )\n",
    ")\n",
    "\n",
    "# Cancel the run.\n",
    "cancellation_token.cancel()\n",
    "\n",
    "try:\n",
    "    result = await run  # This will raise a CancelledError.\n",
    "except asyncio.CancelledError as e:\n",
    "    print(e)\n",
    "    print(\"Task was cancelled.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424ff2f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
